{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "nbpresent": {
     "id": "95b53c4c-ded5-412a-8f70-75c5cdad3bc5"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAADKCAYAAACrHYtRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxxn0ktRx/w9zNdq/68W9yQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f27b079f400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Identify pixels above the threshold\n",
    "# Threshold of RGB > 160 does a nice job of identifying ground pixels only\n",
    "def color_thresh_bak(img, rgb_thresh=(160, 160, 160)):\n",
    "    # Create an array of zeros same xy size as img, but single channel\n",
    "    color_select = np.zeros_like(img[:,:,0])\n",
    "    # Require that each pixel be above all three threshold values in RGB\n",
    "    # above_thresh will now contain a boolean array with \"True\"\n",
    "    # where threshold was met\n",
    "    above_thresh = (img[:,:,0] > rgb_thresh[0]) & (img[:,:,1] > rgb_thresh[1]) & (img[:,:,2] > rgb_thresh[2])\n",
    "    # Index the array of zeros with the boolean array and set to 1\n",
    "    color_select[above_thresh] = 1\n",
    "    # Return the binary image\n",
    "    return color_select\n",
    "\n",
    "def color_thresh(img, rgb_thresh_l=(0, 0, 0), rgb_thresh_u =(255,255,255)):\n",
    "    # Create an array of zeros same xy size as img, but single channel\n",
    "    color_select = np.zeros_like(img[:,:,0])\n",
    "    above_thresh = (img[:,:,0] >= rgb_thresh_l[0]) & (img[:,:,0] <= rgb_thresh_u[0]) & \\\n",
    "    (img[:,:,1] >= rgb_thresh_l[1]) & (img[:,:,1] <= rgb_thresh_u[1]) & \\\n",
    "    (img[:,:,2] >= rgb_thresh_l[2]) & (img[:,:,2] <= rgb_thresh_u[2])\n",
    "    color_select[above_thresh] = 1\n",
    "    return color_select\n",
    "\n",
    "# Define a function to convert from image pixel values to rover-centric pixel\n",
    "def rover_coords(binary_img):\n",
    "    # Identify nonzero pixels\n",
    "    ypos, xpos = binary_img.nonzero()\n",
    "    # Calculate pixel positions with reference to the rover position being at the\n",
    "    # center bottom of the image.\n",
    "    x_pixel = -(ypos - binary_img.shape[0]).astype(np.float)\n",
    "    y_pixel = -(xpos - binary_img.shape[1]/2 ).astype(np.float)\n",
    "    return x_pixel, y_pixel\n",
    "\n",
    "\n",
    "# Define a function to convert to radial coords in rover space\n",
    "def to_polar_coords(x_pixel, y_pixel):\n",
    "    # Convert (x_pixel, y_pixel) to (distance, angle)\n",
    "    # in polar coordinates in rover space\n",
    "    # Calculate distance to each pixel\n",
    "    dist = np.sqrt(x_pixel**2 + y_pixel**2)\n",
    "    # Calculate angle away from vertical for each pixel\n",
    "    angles = np.arctan2(y_pixel, x_pixel)\n",
    "    return dist, angles\n",
    "\n",
    "# Define a function to map rover space pixels to world space\n",
    "def rotate_pix(xpix, ypix, yaw):\n",
    "    # Convert yaw to radians\n",
    "    yaw_rad = yaw * np.pi / 180\n",
    "    xpix_rotated = (xpix * np.cos(yaw_rad)) - (ypix * np.sin(yaw_rad))\n",
    "\n",
    "    ypix_rotated = (xpix * np.sin(yaw_rad)) + (ypix * np.cos(yaw_rad))\n",
    "    # Return the result\n",
    "    return xpix_rotated, ypix_rotated\n",
    "\n",
    "def translate_pix(xpix_rot, ypix_rot, xpos, ypos, scale):\n",
    "    # Apply a scaling and a translation\n",
    "    xpix_translated = (xpix_rot / scale) + xpos\n",
    "    ypix_translated = (ypix_rot / scale) + ypos\n",
    "    # Return the result\n",
    "    return xpix_translated, ypix_translated\n",
    "\n",
    "\n",
    "# Define a function to apply rotation and translation (and clipping)\n",
    "# Once you define the two functions above this function should work\n",
    "def pix_to_world(xpix, ypix, xpos, ypos, yaw, world_size, scale):\n",
    "    # Apply rotation\n",
    "    xpix_rot, ypix_rot = rotate_pix(xpix, ypix, yaw)\n",
    "    # Apply translation\n",
    "    xpix_tran, ypix_tran = translate_pix(xpix_rot, ypix_rot, xpos, ypos, scale)\n",
    "    # Perform rotation, translation and clipping all at once\n",
    "    x_pix_world = np.clip(np.int_(xpix_tran), 0, world_size - 1)\n",
    "    y_pix_world = np.clip(np.int_(ypix_tran), 0, world_size - 1)\n",
    "    # Return the result\n",
    "    return x_pix_world, y_pix_world\n",
    "\n",
    "# Define a function to perform a perspective transform\n",
    "def perspect_transform(img, src, dst):\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    warped = cv2.warpPerspective(img, M, (img.shape[1], img.shape[0]))# keep same size as input image\n",
    "\n",
    "    return warped\n",
    "\n",
    "\n",
    "# Apply the above functions in succession and update the Rover state accordingly\n",
    "def perception_step(Rover):\n",
    "    # Perform perception steps to update Rover()\n",
    "    # TODO:\n",
    "    # NOTE: camera image is coming to you in Rover.img\n",
    "    # 1) Define source and destination points for perspective transform\n",
    "    bottom_offset = 6\n",
    "    dst_size = 5 \n",
    "    image = Rover.img\n",
    "    source = np.float32([[14, 140], [301 ,140],[200, 96], [118, 96]])\n",
    "    destination = np.float32([[image.shape[1]/2 - dst_size, image.shape[0] - bottom_offset],\n",
    "                  [image.shape[1]/2 + dst_size, image.shape[0] - bottom_offset],\n",
    "                  [image.shape[1]/2 + dst_size, image.shape[0] - 2*dst_size - bottom_offset],\n",
    "                  [image.shape[1]/2 - dst_size, image.shape[0] - 2*dst_size - bottom_offset],\n",
    "                  ])\n",
    "\n",
    "    # 2) Apply perspective transform\n",
    "    warped_img = perspect_transform(Rover.img, source, destination)\n",
    "\n",
    "    # 3) Apply color threshold to identify navigable terrain/obstacles/rock samples\n",
    "    rgb_thresh_terrain_l = (160,160,160)\n",
    "    rgb_thresh_rocksample_l = (50,110,0) \n",
    "    rgb_thresh_rocksample_u = (250,250,75)\n",
    "    rgb_thresh_obstacle_l = (0,0,0) # <-------------fix rgb values!\n",
    "    rgb_thresh_obstacle_u = (200,100,200) # <-------------fix rgb values!\n",
    "   \n",
    "    terrain_img = color_thresh(warped_img, rgb_thresh_terrain_l)\n",
    "    rocksample_img = color_thresh(warped_img, rgb_thresh_rocksample_l, rgb_thresh_rocksample_u)\n",
    "    obstacle_img = color_thresh(warped_img, rgb_thresh_obstacle_l, rgb_thresh_obstacle_u)\n",
    "\n",
    "    # 4) Update Rover.vision_image (this will be displayed on left side of screen)\n",
    "    Rover.vision_image[:,:,0] = obstacle_img\n",
    "    Rover.vision_image[:,:,1] = rocksample_img\n",
    "    Rover.vision_image[:,:,2] = terrain_img\n",
    "\n",
    "    # 5) Convert map image pixel values to rover-centric pixel\n",
    "    x_pixel_t, y_pixel_t = rover_coords(terrain_img)\n",
    "    x_pixel_r, y_pixel_r = rover_coords(rocksample_img)\n",
    "    x_pixel_o, y_pixel_o = rover_coords(obstacle_img)\n",
    "\n",
    "    # 6) Convert rover-centric pixel values to world coordinates\n",
    "    x_world_t, y_world_t = pix_to_world(x_pixel_t, y_pixel_t, Rover.pos[0], Rover.pos[1], Rover.yaw, Rover.world_size, Rover.scale)\n",
    "    x_world_r, y_world_r = pix_to_world(x_pixel_r, y_pixel_r, Rover.pos[0], Rover.pos[1], Rover.yaw, Rover.world_size, Rover.scale)\n",
    "    x_world_o, y_world_o = pix_to_world(x_pixel_o, y_pixel_o, Rover.pos[0], Rover.pos[1], Rover.yaw, Rover.world_size, Rover.scale)\n",
    "\n",
    "    # 7) Update Rover worldmap (to be displayed on right side of screen)\n",
    "    Rover.worldmap[y_world_o, x_world_o, 0] += 1\n",
    "    Rover.worldmap[y_world_r, x_world_r, 1] += 1\n",
    "    Rover.worldmap[y_world_t, x_world_t, 2] += 1\n",
    "\n",
    "    # 8) Convert rover-centric pixel positions to polar coordinates\n",
    "    Rover.nav_dists, Rover.nav_angles = to_polar_coords(x_pixel_t,y_pixel_t)\n",
    "\n",
    "    \n",
    "    return Rover\n",
    "\n",
    "\n",
    "ground_truth = mpimg.imread('../calibration_images/map_bw.png')\n",
    "# This next line creates arrays of zeros in the red and blue channels\n",
    "# and puts the map into the green channel.  This is why the underlying\n",
    "# map output looks green in the display image\n",
    "ground_truth_3d = np.dstack((ground_truth*0, ground_truth*255, ground_truth*0)).astype(np.float)\n",
    "\n",
    "class RoverState():\n",
    "    def __init__(self):\n",
    "        self.start_time = None # To record the start time of navigation\n",
    "        self.total_time = None # To record total duration of naviagation\n",
    "        self.img = mpimg.imread('../calibration_images/example_grid1.jpg') # Current camera image\n",
    "        self.pos = (0,0) # Current position (x, y)\n",
    "        self.yaw = 0 # Current yaw angle\n",
    "        self.pitch = 0 # Current pitch angle\n",
    "        self.roll = 0 # Current roll angle\n",
    "        self.vel = 0 # Current velocity\n",
    "        self.steer = 0 # Current steering angle\n",
    "        self.throttle = 0 # Current throttle value\n",
    "        self.brake = 0 # Current brake value\n",
    "        self.nav_angles = 0 # Angles of navigable terrain pixels\n",
    "        self.nav_dists = 0 # Distances of navigable terrain pixels\n",
    "        self.ground_truth = ground_truth_3d # Ground truth worldmap\n",
    "        self.mode = 'forward' # Current mode (can be forward or stop)\n",
    "        self.throttle_set = 0.2 # Throttle setting when accelerating\n",
    "        self.brake_set = 10 # Brake setting when braking\n",
    "        # The stop_forward and go_forward fields below represent total count\n",
    "        # of navigable terrain pixels.  This is a very crude form of knowing\n",
    "        # when you can keep going and when you should stop.  Feel free to\n",
    "        # get creative in adding new fields or modifying these!\n",
    "        self.stop_forward = 50 # Threshold to initiate stopping\n",
    "        self.go_forward = 500 # Threshold to go forward again\n",
    "        self.max_vel = 2 # Maximum velocity (meters/second)\n",
    "        # Image output from perception step\n",
    "        # Update this image to display your intermediate analysis steps\n",
    "        # on screen in autonomous mode\n",
    "        self.vision_image = np.zeros((160, 320, 3), dtype=np.float)\n",
    "        # Worldmap\n",
    "        # Update this image with the positions of navigable terrain\n",
    "        # obstacles and rock samples\n",
    "        self.worldmap = np.zeros((200, 200, 3), dtype=np.float)\n",
    "        self.samples_pos = None # To store the actual sample positions\n",
    "        self.samples_to_find = 0 # To store the initial count of samples\n",
    "        self.samples_located = 0 # To store number of samples located on map\n",
    "        self.samples_collected = 0 # To count the number of samples collected\n",
    "        self.near_sample = 0 # Will be set to telemetry value data[\"near_sample\"]\n",
    "        self.picking_up = 0 # Will be set to telemetry value data[\"picking_up\"]\n",
    "        self.send_pickup = False # Set to True to trigger rock pickup\n",
    "        self.world_size = 200 #<---- added by me\n",
    "        self.scale = 10 #<---------- added by me\n",
    "\n",
    "        \n",
    "# Initialize our rover\n",
    "\n",
    "Rover = RoverState()\n",
    "perception_step(Rover)\n",
    "image2 = plt.imshow(Rover.vision_image[:,:,0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:RoboND]",
   "language": "python",
   "name": "conda-env-RoboND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
